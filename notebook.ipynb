{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to perform Facial Recognition and Analysis\n",
    "\n",
    "Run Face Verification with Deep Learning on DeepFace\n",
    "\n",
    "The following example for face verification shows how simple it is to get it running. Actually, we only pass an image pair as an input, and that’s all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verified': True,\n",
       " 'distance': 1.1102230246251565e-15,\n",
       " 'threshold': 0.4,\n",
       " 'model': 'VGG-Face',\n",
       " 'detector_backend': 'opencv',\n",
       " 'similarity_metric': 'cosine',\n",
       " 'facial_areas': {'img1': {'x': 746, 'y': 154, 'w': 304, 'h': 304},\n",
       "  'img2': {'x': 746, 'y': 154, 'w': 304, 'h': 304}},\n",
       " 'time': 0.85}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verification = DeepFace.verify(img1_path = \"foto_selfie.jpg\", img2_path = \"foto_selfie.jpg\")\n",
    "verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Passed db_path does not exist!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m recognition \u001b[39m=\u001b[39m DeepFace\u001b[39m.\u001b[39;49mfind(img_path \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mfoto_selfie.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m, db_path \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mC:/facial_db\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\alrav\\anaconda3\\lib\\site-packages\\deepface\\DeepFace.py:430\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(img_path, db_path, model_name, distance_metric, enforce_detection, detector_backend, align, normalization, silent)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[39m# -------------------------------\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(db_path) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 430\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPassed db_path does not exist!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    432\u001b[0m target_size \u001b[39m=\u001b[39m functions\u001b[39m.\u001b[39mfind_target_size(model_name\u001b[39m=\u001b[39mmodel_name)\n\u001b[0;32m    434\u001b[0m \u001b[39m# ---------------------------------------\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Passed db_path does not exist!"
     ]
    }
   ],
   "source": [
    "recognition = DeepFace.find(img_path = \"foto_selfie.jpg\", db_path = \"C:/facial_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  5.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': 29,\n",
       " 'region': {'x': 746, 'y': 154, 'w': 304, 'h': 304},\n",
       " 'gender': {'Woman': 1.2206591665744781, 'Man': 98.77933859825134},\n",
       " 'dominant_gender': 'Man',\n",
       " 'emotion': {'angry': 0.8250337973196749,\n",
       "  'disgust': 8.951847191077363e-05,\n",
       "  'fear': 0.05804552819595895,\n",
       "  'happy': 0.010314112521981444,\n",
       "  'sad': 0.6025163204203462,\n",
       "  'surprise': 0.006789371318612686,\n",
       "  'neutral': 98.49720615181849},\n",
       " 'dominant_emotion': 'neutral',\n",
       " 'race': {'asian': 49.31025207042694,\n",
       "  'indian': 12.803339958190918,\n",
       "  'black': 7.909703999757767,\n",
       "  'white': 5.729698017239571,\n",
       "  'middle eastern': 2.723458968102932,\n",
       "  'latino hispanic': 21.523544192314148},\n",
       " 'dominant_race': 'asian'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis = DeepFace.analyze(img_path = \"foto_selfie.jpg\", actions = [\"age\", \"gender\", \"emotion\", \"race\"])\n",
    "analysis[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmax(list(analysis[0]['emotion'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facial recognition model VGG-Face is just built\n",
      "Age model is just built\n",
      "Gender model is just built\n",
      "Emotion model is just built\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Passed db_path does not exist!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m DeepFace\u001b[39m.\u001b[39;49mstream(db_path \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mfoto_selfie.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\alrav\\anaconda3\\lib\\site-packages\\deepface\\DeepFace.py:736\u001b[0m, in \u001b[0;36mstream\u001b[1;34m(db_path, model_name, detector_backend, distance_metric, enable_face_analysis, source, time_threshold, frame_threshold)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[39mif\u001b[39;00m frame_threshold \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    731\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    732\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mframe_threshold must be greater than the value 1 but you passed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    733\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(frame_threshold)\n\u001b[0;32m    734\u001b[0m     )\n\u001b[1;32m--> 736\u001b[0m realtime\u001b[39m.\u001b[39;49manalysis(\n\u001b[0;32m    737\u001b[0m     db_path,\n\u001b[0;32m    738\u001b[0m     model_name,\n\u001b[0;32m    739\u001b[0m     detector_backend,\n\u001b[0;32m    740\u001b[0m     distance_metric,\n\u001b[0;32m    741\u001b[0m     enable_face_analysis,\n\u001b[0;32m    742\u001b[0m     source\u001b[39m=\u001b[39;49msource,\n\u001b[0;32m    743\u001b[0m     time_threshold\u001b[39m=\u001b[39;49mtime_threshold,\n\u001b[0;32m    744\u001b[0m     frame_threshold\u001b[39m=\u001b[39;49mframe_threshold,\n\u001b[0;32m    745\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\alrav\\anaconda3\\lib\\site-packages\\deepface\\commons\\realtime.py:49\u001b[0m, in \u001b[0;36manalysis\u001b[1;34m(db_path, model_name, detector_backend, distance_metric, enable_face_analysis, source, time_threshold, frame_threshold)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEmotion model is just built\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[39m# -----------------------\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39m# call a dummy find function for db_path once to create embeddings in the initialization\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m DeepFace\u001b[39m.\u001b[39;49mfind(\n\u001b[0;32m     50\u001b[0m     img_path\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mzeros([\u001b[39m224\u001b[39;49m, \u001b[39m224\u001b[39;49m, \u001b[39m3\u001b[39;49m]),\n\u001b[0;32m     51\u001b[0m     db_path\u001b[39m=\u001b[39;49mdb_path,\n\u001b[0;32m     52\u001b[0m     model_name\u001b[39m=\u001b[39;49mmodel_name,\n\u001b[0;32m     53\u001b[0m     detector_backend\u001b[39m=\u001b[39;49mdetector_backend,\n\u001b[0;32m     54\u001b[0m     distance_metric\u001b[39m=\u001b[39;49mdistance_metric,\n\u001b[0;32m     55\u001b[0m     enforce_detection\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     56\u001b[0m )\n\u001b[0;32m     57\u001b[0m \u001b[39m# -----------------------\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39m# visualization\u001b[39;00m\n\u001b[0;32m     59\u001b[0m freeze \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alrav\\anaconda3\\lib\\site-packages\\deepface\\DeepFace.py:430\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(img_path, db_path, model_name, distance_metric, enforce_detection, detector_backend, align, normalization, silent)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[39m# -------------------------------\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(db_path) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 430\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPassed db_path does not exist!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    432\u001b[0m target_size \u001b[39m=\u001b[39m functions\u001b[39m.\u001b[39mfind_target_size(model_name\u001b[39m=\u001b[39mmodel_name)\n\u001b[0;32m    434\u001b[0m \u001b[39m# ---------------------------------------\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Passed db_path does not exist!"
     ]
    }
   ],
   "source": [
    "DeepFace.stream(db_path = \"foto_selfie.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab4cfb695e4995928d8d48b937410e7989a45ba361d6003efd8e9b7b9498f677"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
